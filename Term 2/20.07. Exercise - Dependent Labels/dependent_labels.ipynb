{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlapping Labels\n",
    "\n",
    "In this exercise, we're going to **simulate** the issue we encounter when training machine learning models using targets that are returns that _overlap in time_. The core issue is that these labels are correlated and in fact _redundant_. We'll see what impact this has on our machine learning algorithm, and we'll have the opportunity to implement some of the solutions to the problem that we described in the lectures, and will later encounter in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Let's load up a small dataset of artificial \"toy\" data that we can play with. The columns in these data are `A`, `B`, `C` and `D`. We will use the `E` column as targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dependent_labels_dataset.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create redundancy in the data\n",
    "In order to illustrate the effect of redundancy in the data, we are going to deliberately create an extreme version of this condition by **duplicating each row in the data 5 times**, using the function `create_redundant_data` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_duplicates = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_redundant_data(df, num_duplicates):\n",
    "    \"\"\"\n",
    "    From the existing dataset, create a new dataset in which every original row is exactly duplicated `num_duplicates` times. \n",
    "    Re-order this new dataset according to the order of the original index.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "        The original dataset.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    redundant_df : pandas DataFrame\n",
    "        The new, redundant dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redundant_df = create_redundant_data(df, num_duplicates)\n",
    "redundant_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function for scoring the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_score(m, X_train, y_train, X_valid, y_valid):\n",
    "    '''\n",
    "    Take in the model and training and validation datasets, and return the training accuracy score, validation\n",
    "    accuracy score, and out-of-bag score. Furthermore, print each of these results.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    m : RandomForestClassifier instance\n",
    "        The trained model.\n",
    "        \n",
    "    X_train : pandas DataFrame\n",
    "        The training features.\n",
    "        \n",
    "    y_train : pandas Series\n",
    "        The training labels.\n",
    "        \n",
    "    X_valid : pandas DataFrame\n",
    "        The validation features.\n",
    "        \n",
    "    y_valid : pandas Series\n",
    "        The validation labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    train_score : float\n",
    "        The mean training accuracy.\n",
    "        \n",
    "    valid_score : float\n",
    "        The mean validation accuracy.\n",
    "        \n",
    "    oob_score : float\n",
    "        The out-of-bag score.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # TODO: Implement\n",
    "    \n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train, valid and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_splits(df, features, target, split_valid=0.20, split_test=0.20):\n",
    "    temp = df.dropna()\n",
    "    \n",
    "    X = temp[features].copy()\n",
    "    y = temp[target].copy()\n",
    "\n",
    "    train_end = int(X.shape[0]*(1-split_valid-split_test))\n",
    "    valid_end = train_end + int(X.shape[0]*split_valid)\n",
    "\n",
    "    X_train, X_valid, X_test = X.iloc[:train_end,], X.iloc[(train_end+1):valid_end,], X.iloc[(valid_end+1):]\n",
    "    y_train, y_valid, y_test = y.iloc[:train_end,], y.iloc[(train_end+1):valid_end,], y.iloc[(valid_end+1):]\n",
    "    \n",
    "    return X, X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['A', 'B', 'C', 'D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, X_train, X_valid, X_test, y_train, y_valid, y_test = make_splits(\n",
    "    redundant_df,\n",
    "    features,\n",
    "    'E'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train one tree, take a look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def instantiate_and_fit_one_tree(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Instantiate a single decision tree and fit it on the training data. Return the fitted classifier.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : pandas DataFrame\n",
    "        The training features.\n",
    "        \n",
    "    y_train : pandas Series\n",
    "        The training labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    clf : DecisionTreeClassifier\n",
    "        The fitted classifier instance.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = instantiate_and_fit_one_tree(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "def export_graph(classifier, feature_names):\n",
    "    \"\"\"\n",
    "    First, export the dot data from the fitted classifier. Then, create a graphviz Source object from the dot data,\n",
    "    and return it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    classifier : DecisionTreeClassifier\n",
    "        The single decision tree you created and fit above.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    graph : graphviz Source object\n",
    "        The Source object created with the graph information.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display the single decision tree graph in the notebook\n",
    "graph = export_graph(clf, features)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redundant labels\n",
    "Let's see what happens when we train a full random forest on these redundant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def instantiate_and_fit_a_rf(n_estimators, X_train, y_train, min_samples_leaf=5):\n",
    "    \"\"\"\n",
    "    Instantiate a random forest classifier and fit it on the training data. Return the fitted classifier.\n",
    "    Make sure you use bootstrapping and calculate an out-of-bag score. Set `random_state` equal to an integer so that\n",
    "    when you fit the model again you get the same result. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_estimators : int\n",
    "        The number of trees.\n",
    "    \n",
    "    X_train : pandas DataFrame\n",
    "        The training features.\n",
    "        \n",
    "    y_train : pandas Series\n",
    "        The training labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    clf : RandomForestClassifier\n",
    "        The fitted classifier instance.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = []\n",
    "valid_score = []\n",
    "oob_score = []\n",
    "tree_sizes = [10, 50, 100, 250]\n",
    "\n",
    "for trees in tqdm(tree_sizes):\n",
    "    clf_red = instantiate_and_fit_a_rf(trees, X_train, y_train)\n",
    "    \n",
    "    tr, va, oob = model_score(clf_red, X_train, y_train, X_valid, y_valid)\n",
    "    train_score.append(tr); valid_score.append(va); oob_score.append(oob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_results(tree_sizes, train_score, oob_score, valid_score, title, y_range):\n",
    "    plt.plot(tree_sizes, train_score, 'xb-');\n",
    "    plt.plot(tree_sizes, oob_score, 'xg-');\n",
    "    plt.plot(tree_sizes, valid_score, 'xr-');\n",
    "    plt.title(title);\n",
    "    plt.xlabel('Number of Trees');\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['train','oob', 'valid'])\n",
    "    plt.ylim(y_range[0], y_range[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_range = []\n",
    "y_range.append(0.45)\n",
    "y_range.append(1.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(tree_sizes, train_score, oob_score, valid_score, 'Random Forest with Redundant Data (accuracy): train, validation, oob', y_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you can see from this run is that the OOB score virtually tracks the training score because the OOB data contains the same information as the training data. The validation score, calculated on unseen data, is much lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution #1: use every 5th row\n",
    "In this section, implement the first solution to the redundancy issue by sub-sampling every 5th row of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_subsampled_dataset(num_duplicates, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Create the sub-sampled dataset according to the first solution proposed to the problem of overlapping labels. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_duplicates : int\n",
    "        The number of duplications made earlier.\n",
    "    \n",
    "    X_train : pandas DataFrame\n",
    "        The training features.\n",
    "        \n",
    "    y_train : pandas Series\n",
    "        The training labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_train_sub : pandas DataFrame\n",
    "        The training features, subsampled.\n",
    "        \n",
    "    y_train_sub : pandas Series\n",
    "        The training labels, subsampled.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sub, y_train_sub = create_subsampled_dataset(5, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = []\n",
    "valid_score = []\n",
    "oob_score = []\n",
    "tree_sizes = [10, 50, 100, 250]\n",
    "\n",
    "for trees in tqdm(tree_sizes):\n",
    "    clf_sub = instantiate_and_fit_a_rf(trees, X_train_sub, y_train_sub)\n",
    "    \n",
    "    tr, va, oob = model_score(clf_sub, X_train_sub, y_train_sub, X_valid, y_valid)\n",
    "    train_score.append(tr); valid_score.append(va); oob_score.append(oob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(tree_sizes, train_score, oob_score, valid_score, 'Random Forest on Redundant Data, with Subsampling (accuracy): train, validation, oob', y_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of our artificial dataset, this completely removes the redundancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution #2: reduce bag size\n",
    "In this section, implement the second solution we proposed—to use `BaggingClassifier` to randomly draw a smaller fraction of the original dataset's rows when creating each tree's dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_clf = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def instantiate_and_fit_a_BaggingClassifier(n_estimators, base_estimator, X_train, y_train, max_samples = 0.2):\n",
    "    \"\"\"\n",
    "    Instantiate a Bagging Classifier and fit it on the training data. Return the fitted classifier.\n",
    "    Make sure you use bootstrapping and calculate an out-of-bag score. Set `random_state` equal to an integer so that\n",
    "    when you fit the model again you get the same result. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_estimators : int\n",
    "        The number of trees.\n",
    "        \n",
    "    base_estimator : DecisionTreeClassifier\n",
    "        The base estimator of the BaggingClassifier.\n",
    "        \n",
    "    max_samples : float\n",
    "        The percentage of the number of original rows to draw for each bag.\n",
    "    \n",
    "    X_train : pandas DataFrame\n",
    "        The training features.\n",
    "        \n",
    "    y_train : pandas Series\n",
    "        The training labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    clf : BaggingClassifier\n",
    "        The fitted classifier instance.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = []\n",
    "valid_score = []\n",
    "oob_score = []\n",
    "tree_sizes = [10, 50, 100, 250]\n",
    "\n",
    "for trees in tqdm(tree_sizes):\n",
    "    clf_bag = instantiate_and_fit_a_BaggingClassifier(trees, base_clf, X_train, y_train)\n",
    "    \n",
    "    tr, va, oob = model_score(clf_bag, X_train, y_train, X_valid, y_valid)\n",
    "    train_score.append(tr); valid_score.append(va); oob_score.append(oob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(tree_sizes, train_score, oob_score, valid_score, 'Random Forest on Redundant Data, with Reduced Bag Size (accuracy): train, validation, oob', y_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, in the case of this small artificial dataset, this helped but didn't fully resolve the problem. The OOB score still vastly overestimates the validation score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution #3: bagged non-overlapping labels\n",
    "Finally, let's look at the last solution we proposed to this problem. We'll do this one for you for this small exercise, but you'll have the opportunity to work on it yourself later. We will fit separate models on each non-redundant subset of data, and then ensemble them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.validation import has_fit_parameter, check_is_fitted\n",
    "from sklearn.utils.metaestimators import _BaseComposition\n",
    "from sklearn.utils import Bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NoOverlapVoter(VotingClassifier):\n",
    "    def __init__(self, base_estimator, overlap_increment=5):\n",
    "        self.est_list = []\n",
    "        for i in range(overlap_increment):\n",
    "            self.est_list.append(('clf'+str(i), clone(base_estimator)))\n",
    "        self.overlap_increment = overlap_increment\n",
    "        super().__init__(\n",
    "            self.est_list,\n",
    "            voting='soft'\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def oob_score_(self):\n",
    "        oob = 0\n",
    "        for clf in self.estimators_:\n",
    "            oob = oob + clf.oob_score_\n",
    "        return oob / len(self.estimators_)\n",
    "    \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        names, clfs = zip(*self.estimators)\n",
    "        self._validate_names(names)\n",
    "\n",
    "        self.le_ = LabelEncoder().fit(y)\n",
    "        self.classes_ = self.le_.classes_\n",
    "        self.estimators_ = []\n",
    "\n",
    "        transformed_y = self.le_.transform(y)\n",
    "\n",
    "        self.estimators_ = []\n",
    "        for i in range(self.overlap_increment):\n",
    "            self.estimators_.append(\n",
    "                clfs[i].fit(X[i::self.overlap_increment], transformed_y[i::self.overlap_increment])\n",
    "            )\n",
    "        \n",
    "        self.named_estimators_ = Bunch(**dict())\n",
    "        for k, e in zip(self.estimators, self.estimators_):\n",
    "            self.named_estimators_[k[0]] = e\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = []\n",
    "valid_score = []\n",
    "oob_score = []\n",
    "tree_sizes = [10, 50, 100, 250]\n",
    "\n",
    "for trees in tqdm(tree_sizes):\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=trees,\n",
    "        max_features='sqrt',\n",
    "        min_samples_leaf=5,\n",
    "        bootstrap=True,\n",
    "        oob_score=True,\n",
    "        n_jobs=-1,\n",
    "        criterion='entropy',\n",
    "        verbose=0,\n",
    "        random_state=0\n",
    "    )\n",
    "    \n",
    "    clf_nov = NoOverlapVoter(clf)\n",
    "    clf_nov.fit(X_train.reset_index()[['A','B','C','D']], y_train)\n",
    "    t, v, o = model_score(clf_nov, X_train, y_train, X_valid, y_valid)\n",
    "    train_score.append(t); valid_score.append(v); oob_score.append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(tree_sizes, train_score, oob_score, valid_score, 'Random Forest on Redundant Data, with NoOverlapVoter (accuracy): train, validation, oob', y_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in the case of this artificial dataset, this method performs as well as the first method, but this makes sense because each of the separate classifiers has the exact same information as the others. Combining them together should not yield much performance enhancement. You can then compare this result to the result that you'll see in the project, when this method is applied to real financial data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Check the performance on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Finally, let's look at the performance of the third method on the held-out test set. For this, we'll train on all of the previous training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, X_train, X_valid, X_test, y_train, y_valid, y_test = make_splits(\n",
    "    redundant_df,\n",
    "    features,\n",
    "    'E',\n",
    "    split_valid = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(\n",
    "        n_estimators=150,\n",
    "        max_features='sqrt',\n",
    "        min_samples_leaf=5,\n",
    "        bootstrap=True,\n",
    "        oob_score=True,\n",
    "        n_jobs=-1,\n",
    "        criterion='entropy',\n",
    "        verbose=False,\n",
    "        random_state=0\n",
    "    )\n",
    "    \n",
    "clf_nov = NoOverlapVoter(clf)\n",
    "clf_nov.fit(X_train.reset_index()[['A','B','C','D']], y_train)\n",
    "t, v, o = model_score(clf_nov, X_train, y_train, X_test, y_test)\n",
    "train_score.append(t); valid_score.append(v); oob_score.append(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see that the result on the held-out test set has improved somewhat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're stuck, check out the [solution notebook](dependent_labels_solution.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
